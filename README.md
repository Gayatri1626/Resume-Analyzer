Here's a `README.md` file for your **Resume Data Analysis** project:

---

# ğŸ“„ Resume Data Analysis

## ğŸš€ **Project Overview**
The **Resume Data Analysis** project extracts, analyzes, and evaluates resumes in PDF format. It identifies sections, extracts contact information, extracts skills, and calculates quality scores based on experience, education, and skills match with specific job roles. The analysis results are saved to JSON format for easy storage and retrieval.

---

## ğŸ“š **Features**

âœ… Extracts text from PDF resumes  
âœ… Identifies and extracts key sections: `Contact`, `Summary`, `Experience`, `Education`, `Skills`, etc.  
âœ… Extracts action verbs using **WordNet** and **NLTK**  
âœ… Calculates quality scores:
- **Skill match score:** Matches resume skills with job-specific skills  
- **Experience score:** Analyzes years and months of experience  
- **Education score:** Evaluates the degree and relevant fields  
âœ… Saves analysis results to a JSON file with a timestamp  
âœ… Supports multiple job profiles: `Data Scientist`, `AI Engineer`, `Software Developer`  

---

## ğŸ› ï¸ **Tech Stack**

- **Python Libraries:**  
  - `PyPDF2` â†’ PDF extraction  
  - `spaCy` â†’ NLP processing  
  - `NLTK` â†’ Natural language processing (WordNet and POS tagging)  
  - `sklearn` â†’ TF-IDF vectorizer for text analysis  
  - `datetime` â†’ Timestamp for saving analysis results  
- **File Format:**  
  - PDF input files  
  - JSON output files  

---

## ğŸ”¥ **Installation**

1. **Clone the Repository**
```bash
git clone <repository_url>
cd resume-data-analysis
```

2. **Install Dependencies**
```bash
pip install -r requirements.txt
```

3. **Download NLTK Resources**
```python
import nltk
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')
```

---

## ğŸ“Š **Usage**

1. **Run the Script**
```bash
python resume_analyzer.py
```

2. **Input PDF Resume**
- Place the PDF file in the working directory
- Update the PDF file path in the script:
```python
pdf_path = "path/to/resume.pdf"
```

3. **Output**
- The extracted sections, skills, and scores will be saved as a JSON file:
```json
{
  "timestamp": "2025-03-19T12:45:32",
  "analysis": {
    "sections": {
      "CONTACT": "John Doe\njohn.doe@email.com\n+1-234-567-890",
      "EXPERIENCE": "...",
      "SKILLS": "Python, SQL, Data Analysis"
    },
    "skill_match_score": 35.0,
    "experience_score": 25.0,
    "education_score": 30.0
  }
}
```

---

## âœ… **Scoring Criteria**

- **Skill Match Score:**  
  - Compares extracted skills with job-specific skills  
  - Max score: **40 points**

- **Experience Score:**  
  - Based on experience duration (years and months)  
  - Max score: **30 points**

- **Education Score:**  
  - Degree level and relevant fields  
  - Max score: **30 points**

---

## ğŸ› ï¸ **Customization**

- **Add new job profiles**
  - Edit the `self.job_skills` dictionary in the `ResumeAnalyzer` class:
```python
self.job_skills = {
    'data_scientist': ['python', 'sql', 'machine learning'],
    'ai_engineer': ['tensorflow', 'pytorch', 'nlp'],
    'software_developer': ['java', 'aws', 'docker']
}
```

- **Update Section Patterns**
  - Modify `self.section_patterns` to add or customize section names.

---

## âš™ï¸ **Directory Structure**
```
/resume-data-analysis  
 â”œâ”€â”€ resume_analyzer.py        # Main script  
 â”œâ”€â”€ requirements.txt          # Dependencies  
 â”œâ”€â”€ sample_resume.pdf         # Sample PDF resume  
 â”œâ”€â”€ output.json               # Analysis result in JSON  
 â”œâ”€â”€ README.md                 # Documentation  
```

---

## ğŸ“Œ **To-Do List**

- [ ] Improve NLP accuracy for section extraction  
- [ ] Add support for more job profiles  
- [ ] Integrate visualizations (matplotlib) for resume scoring  
- [ ] Add functionality to compare multiple resumes  

---

## ğŸ“ **License**
This project is licensed under the MIT License.  

---

## âœ¨ **Contributors**
- [Gayatri Ghorpade](https://github.com/your-github-profile)  

---

âœ… **Feel free to contribute and improve this project!**
